# Pinot Table Configuration

|  **Table Config** | **Schema to define Pinot table configurations** |
|  ------ | ------ |
|  `tableName` | name of the table |
|  `tableType` | type of the table.<br/>Accepted values:<br/>1.OFFLINE<br/>2.REALTIME |
|  **Segment validation config** | **[segmentsConfig]define pinot segment properties and lifecycle** |
|  `retentionTimeUnit` | TTL time unit of the Pinot Segments.<br/>Accepted values<br/>1.NANOSECONDS<br/>2.MICROSECONDS<br/>3.MILLISECONDS<br/>4.SECONDS<br/>5.MINUTES<br/>6.HOURS<br/>7.DAYS |
|  `retentionTimeValue` | TTL value for the Pinot Segments |
|  `segmentPushFrequency` | Frequency to push segment to persistence storage? |
|  `segmentPushType` | type of the segment push<br/>Accepted Values<br/>1.APPEND<br/>2.REFRESH |
|  `replication` | For high-level kafka consumers, <br/>the number of replicas should be same as num server instances |
|  `schemaName` | schema name of the Pinot table |
|  `timeColumnName` | timestamp column in pinot schema |
|  `timeType` | time unit of the timeColumnName.<br/>Accepted Values:<br/>1.DAYS_SINCE_EPOCH<br/>2.HOURS_SINCE_EPOCH<br/>3.MINUTES_SINCE_EPOCH<br/>4.SECONDS_SINCE_EPOCH |
|  `replicasPerPartition` | Number of replicas per partition of low-level kafka consumers. <br/>This config is used for realtime tables only |
|  `segmentAssignmentStrategy` | Strategy to assign a segment to an instances.<br/>Accepted Values<br/>1.BalanceNumSegmentAssignmentStrategy <br/>[Assigns a segment to the instance that has least number of segments.]<br/>2.BucketizedSegmentStrategy <br/>[Assigns a segment to the instance that has same sharding key.]<br/>3.RandomAssignmentStrategy <br/>[Random assign segment to instances.]<br/>4.ReplicaGroupSegmentAssignmentStrategy<br/> [segment assignment strategy based on the concept of a replica group.] |
|  `replicaGroupStrategyConfig` | subset of [segmentsConfig]. <br/>applicable if you chooseReplicaGroupSegmentAssignmentStrategyas your <br/>segment assignment configuration |
|  `partitionColumn` | ??? |
|  `numInstancesPerPartition` | ??? |
|  `mirrorAssignmentAcrossReplicaGroups` | ??? |
|  `starTreeConfig` | star tree configuration.subset of [segmentsConfig] |
|  `maxLeafRecords` | The upper bound on the number of leaf records to be scanned for any query. <br/>Default Value: 100000 |
|  `dimensionsSplitOrder` | Dimension split order(if null or absent, descending w.r.t. dimension cardinality) |
|  `skipStarNodeCreationForDimensions` | Dimensions for which to exclude star nodes at split |
|  `skipMaterializationForDimensions` | ??? |
|  `excludeSkipMaterializationDimensionsForStarTreeIndex` | ??? Default Value: 10000 |
|  `skipMaterializationCardinality` | ??? |
|  `hllConfig` | HllConfig is used at segment generation. subset of [segmentsConfig] |
|  `hllLog2m` | defines the accuracy of the counter.The larger the log2m the better the accuracy.<br/>accuracy = 1.04/sqrt(2^log2m)<br/>Default Value: 8 |
|  `hllDeriveColumnSuffix` | suffix name for the derived columns. Default Value:_hll |
|  `columnsToDeriveHllFields` | a comma separated column names to be calculated for hll |
|  **tenantConfig** | **[tenants]Tenant configuration.[TODO: Add tenant definition in Pinot core terminology]** |
|  server | server tenant tags |
|  broker | broker tenant tags |
|  **indexingConfig** | **[tableIndexConfig]configuration to define how the schema should be indexed** |
|  `invertedIndexColumns` | array of columns to be inverted indexed |
|  `autoGeneratedInvertedIndex` | ??? |
|  `sortedColumn` | array of columns to be sorted, Note: [you specify multiple sorted columns, <br/>but only consider the first one for now, since secondary sort is not yet implemented]. <br/>The first column name will be used for sorting. The column should not be amulti-valuedfield |
|  `loadMode` | Read segments either in heap or memory map.<br/>Accepted Values:<br/>1. heap<br/>2. mmap<br/>Default Value:heap<br/>Recommended:mmap |
|  `segmentFormatVersion` | Segment version type.<br/>Accepted Values:<br/>1.v1 [Each index in a separate file]<br/>2.v2 [Use bit packing library instead of custom bit set for forward index format]<br/>3.v3 [All the indexes in a single file]<br/><br/>Default: v3<br/>Recommended: v3 |
|  `columnMinMaxValueGeneratorMode` | min/ max stats generator mode for each column during the index creation<br/>Accepted Values:<br/>1. NONE (do not generate stats on any column)<br/>2. TIME (generate on time column only)<br/>3. NON_METRIC (generate on time/dimension columns)<br/>4. ALL (generate on all columns)<br/>Default: TIME |
|  `noDictionaryColumns` | List of fields name excluded from dictionary indexing. |
|  `onHeapDictionaryColumns` | List of columns to be loaded to the java heap for dictionary indexing. |
|  `starTreeIndexSpec` | Question: Find out why do we have the starTreeIndexSpec again here instead of segments config? |
|  `segmentPartitionConfig` | partition configuration for a given column. subset of[indexingConfig]<br/>`{<column name> : <partition function> }`<br/>valid partition function:modulo |
|  `streamConfigs` | configuration for stream source. subset of[indexingConfig] |
|  `streamType` | Kafka(Default implementation) |
|  `realtime.segment.flush.threshold.time` | Time threshold that will keep the realtime segment open for before we convert it into an offline segment |
|  `realtime.segment.commit.timeoutSeconds` | Time threshold that controller will wait for the segment to be built by the server. |
|  `realtime.segment.flush.threshold.size` | Row count flush threshold for realtime segments. |
|  `stream.kafka.topic.name` | kafka topic name to consume by Pinot |
|  `stream.kafka.consumer.type` | Valid options:<br/>1. simple<br/>2. highlevel<br/>Recommended:simple |
|  `stream.kafka.decoder.class.name` | Decoded class name to decode the stream data |
|  `stream.kafka.decoder.prop` | any additional properties to pass through for stream.kafka.decoded.class |
|  `stream.kafka.connection.timeout.ms` | kafka broker connection timeout |
|  `stream.kafka.fetch.timeout.ms` | connection timeout while fetching the data from Kafka |
|  `stream.kafka.zk.broker.url` | Kafka zookeeper url |
|  `stream.kafka.broker.list` | kafka brokers url |
|  `stream.kafka.consumer.factory.class.name` | kafka consumer class. <br/>for simple consumercom.linkedin.pinot.core.realtime.impl.kafka.SimpleConsumerFactory |
|  `stream.auto.offset.reset` | kafka offset reset property |
|  **tableCustomConfig** | **[metadata]Key value pair of any custom config to pass.** |
|  **quotaConfig** | **[quota]Storage quota configuration for the table** |
|  `storage` | Human readable storage size format.<br/>(e.g)“128M” or“1G”<br/>Default: No Quota |
|  **taskConfig** | **[task] ?????** |
|  **routingConfig** | **[routing] ???** |
|   |  |